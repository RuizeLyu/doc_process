import os
import pandas as pd
from docx import Document
from docx.shared import Pt, RGBColor
from docx.oxml.ns import qn
from pathlib import Path
from docx.enum.text import WD_ALIGN_PARAGRAPH
import requests
import json
import time
import csv

# ==============================
# ğŸ”‘ Qwen API é…ç½®
# ==============================
QWEN_API_KEY = "sk-a9a56d27bc1845349cc65ca500743d4c"
QWEN_MODEL = "qwen-max"
API_URL = "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation"

HEADERS = {
    "Authorization": f"Bearer {QWEN_API_KEY}",
    "Content-Type": "application/json"
}

def call_qwen(prompt: str, max_retries=3) -> str:
    """
    è°ƒç”¨ DashScope Qwen APIï¼ˆæ­£ç¡®æ ¼å¼ï¼‰
    æ”¯æŒ qwen-max / qwen-plus / qwen-turbo
    """
    payload = {
        "model": QWEN_MODEL,
        "input": {
            "messages": [
                {"role": "user", "content": prompt}
            ]
        },
        "parameters": {
            "max_tokens": 500,
            "temperature": 0.3,
            "top_p": 0.8
        }
    }

    for attempt in range(max_retries):
        try:
            response = requests.post(API_URL, headers=HEADERS, data=json.dumps(payload))
            if response.status_code == 200:
                result = response.json()
                # âœ… DashScope Qwen è¿”å›çš„æ˜¯ output.textï¼Œä¸æ˜¯ choicesï¼
                return result['output']['text'].strip()
            else:
                err_msg = response.json().get("message", response.text)
                print(f"âŒ API é”™è¯¯ (å°è¯• {attempt + 1}/{max_retries}): {response.status_code} - {err_msg}")
        except Exception as e:
            print(f"âš ï¸ è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{max_retries}): {e}")
        time.sleep(1)
    return "ã€ç­”æ¡ˆã€‘æ­¤å¤„åº”ç”±å¤§æ¨¡å‹ç”Ÿæˆï¼Œä½† API è°ƒç”¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"

def generate_scene_summary(scene_name: str, steps: list) -> str:
    steps_text = "\n".join([f"{i+1}. {step}" for i, step in enumerate(steps)])
    prompt = f"""ä½ æ˜¯ä¸€ä¸ª HR ç³»ç»Ÿä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹æµ‹è¯•æ­¥éª¤ï¼Œæ€»ç»“å‡ºè¯¥åœºæ™¯çš„æ•´ä½“ä¸šåŠ¡æµç¨‹ã€‚

è¦æ±‚ï¼š
- è¾“å‡ºæ ¼å¼ä¸ºä¸€æ®µè¿è´¯è‡ªç„¶è¯­è¨€
- ä¸è¦ç¼–å·ã€ä¸è¦ bullet points
- åŒ…å«ä¸»è¦è§’è‰²ï¼ˆå¦‚HRã€ç”¨äººéƒ¨é—¨ï¼‰ã€å…³é”®ç¯èŠ‚ã€ä¸šåŠ¡ç›®çš„
- é•¿åº¦æ§åˆ¶åœ¨ 300 å­—ä»¥å†…
- ä¸è¦ç¼–é€ æœªæåŠçš„åŠŸèƒ½

åœºæ™¯åç§°ï¼š{scene_name}
æµ‹è¯•æ­¥éª¤åˆ—è¡¨ï¼š
{steps_text}

è¯·è¾“å‡ºæ€»ç»“ï¼š"""
    return call_qwen(prompt)

def process_excel_file(excel_file: str):
    """
    å¤„ç† Excel æ–‡ä»¶ï¼ŒåŒæ—¶ç”Ÿæˆ DOCX å’Œ CSV æ–‡ä»¶
    """
    print(f"\nğŸš€ å¼€å§‹å¤„ç† Excel æ–‡ä»¶: {excel_file}")
    
    # é…ç½®
    EXCEL_FILE = excel_file
    OUTPUT_FOLDER = "result"
    os.makedirs(OUTPUT_FOLDER, exist_ok=True)
    
    main_title = Path(EXCEL_FILE).stem
    
    # å‡†å¤‡å­˜å‚¨é—®ç­”å¯¹çš„åˆ—è¡¨ï¼ˆç”¨äº CSVï¼‰
    qa_pairs = []
    
    # åˆ›å»º DOCX
    doc = Document()
    
    # === å…¨å±€å­—ä½“ ===
    style = doc.styles['Normal']
    font = style.font
    font.name = 'SimSun'
    font.size = Pt(12)
    style._element.rPr.rFonts.set(qn('w:eastAsia'), 'Microsoft YaHei')
    
    # === ä¸»æ ‡é¢˜ ===
    title = doc.add_heading(main_title, level=0)
    title_run = title.runs[0]
    title_run.font.size = Pt(30)
    title_run.font.bold = True
    title_run.font.color.rgb = RGBColor(0, 0, 0)
    title.alignment = WD_ALIGN_PARAGRAPH.LEFT
    
    # å¤„ç†æ¯ä¸ª Sheet
    with pd.ExcelFile(EXCEL_FILE) as xls:
        for sheet_name in xls.sheet_names:
            print(f"ğŸ”„ å¤„ç†å·¥ä½œè¡¨: {sheet_name}")

            df_raw = pd.read_excel(xls, sheet_name=sheet_name, header=None, dtype=str)
            df_raw = df_raw.fillna("")

            if df_raw.empty:
                print(f"âš ï¸ è·³è¿‡ç©ºè¡¨: {sheet_name}")
                continue

            nrows, ncols = df_raw.shape
            col_map = {}
            data_start_row = -1

            # === æ‰¾è¡¨å¤´ ===
            for i in range(nrows):
                row = df_raw.iloc[i]
                non_empty_cols = [(j, str(row[j]).strip()) for j in range(ncols) if str(row[j]).strip() != ""]
                if not non_empty_cols:
                    continue
                values = [v for _, v in non_empty_cols]
                indices = [j for j, _ in non_empty_cols]
                
                # å°è¯•ä¸åŒçš„è¡¨å¤´æ ¼å¼
                target_fields_list = [
                    ["æµ‹è¯•è§’è‰²", "æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®/ç‰¹æ®Šä¿¡æ¯", "é¢„æœŸç»“æœ"],
                    ["æµ‹è¯•è§’è‰²", "æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®", "é¢„æœŸç»“æœ"],
                    ["æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®/ç‰¹æ®Šä¿¡æ¯", "é¢„æœŸç»“æœ"],
                    ["æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®", "é¢„æœŸç»“æœ"],
                    ["æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®/ç‰¹æ®Šä¿¡æ¯"],
                    ["æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®"],
                    ["å…³é”®ç¯èŠ‚", "æ“ä½œè§’è‰²", "æ“ä½œæ­¥éª¤", "è¾“å…¥æ•°æ®", "é¢„æœŸç»“æœ"],
                    ["æµ‹è¯•è§’è‰²", "æµ‹è¯•æ­¥éª¤", "è¾“å…¥æ•°æ®", "é¢„æœŸç»“æœ"],
                    ["æ“ä½œè§’è‰²", "æµ‹è¯•æ­¥éª¤", "åŠŸèƒ½è·¯å¾„", "è¾“å…¥æ•°æ®", "é¢„æœŸç»“æœ"]
                ]
                
                found = False
                for target_fields in target_fields_list:
                    if all(f in values for f in target_fields):
                        for f in target_fields:
                            col_map[f] = indices[values.index(f)]
                        data_start_row = i + 1
                        found = True
                        break
                
                if found:
                    break

            if not col_map or data_start_row == -1:
                print(f"âš ï¸ æœªæ‰¾åˆ°è¡¨å¤´ï¼Œè·³è¿‡: {sheet_name}")
                continue

            # === æå–æœ‰æ•ˆæ•°æ® ===
            data_rows = []
            for i in range(data_start_row, nrows):
                row = df_raw.iloc[i]
                try:
                    # å°è¯•è·å–æµ‹è¯•è§’è‰²ï¼Œå¯èƒ½æœ‰ä¸åŒçš„å­—æ®µå
                    if "æµ‹è¯•è§’è‰²" in col_map:
                        test_role = str(row[col_map["æµ‹è¯•è§’è‰²"]]).strip()
                    elif "æ“ä½œè§’è‰²" in col_map:
                        test_role = str(row[col_map["æ“ä½œè§’è‰²"]]).strip()
                    else:
                        test_role = ""
                    
                    # å°è¯•è·å–æµ‹è¯•æ­¥éª¤ï¼Œå¯èƒ½æœ‰ä¸åŒçš„å­—æ®µå
                    if "æµ‹è¯•æ­¥éª¤" in col_map:
                        step = str(row[col_map["æµ‹è¯•æ­¥éª¤"]]).strip()
                    elif "æ“ä½œæ­¥éª¤" in col_map:
                        step = str(row[col_map["æ“ä½œæ­¥éª¤"]]).strip()
                    elif "å…³é”®ç¯èŠ‚" in col_map:
                        step = str(row[col_map["å…³é”®ç¯èŠ‚"]]).strip()
                    else:
                        step = ""
                    
                    # å°è¯•è·å–åŠŸèƒ½è·¯å¾„ï¼Œå¯èƒ½ä¸å­˜åœ¨
                    if "åŠŸèƒ½è·¯å¾„" in col_map:
                        path = str(row[col_map["åŠŸèƒ½è·¯å¾„"]]).strip()
                    else:
                        path = ""
                    
                    # å°è¯•è·å–è¾“å…¥æ•°æ®ï¼Œå¯èƒ½æœ‰ä¸åŒçš„å­—æ®µå
                    if "è¾“å…¥æ•°æ®/ç‰¹æ®Šä¿¡æ¯" in col_map:
                        input_data = str(row[col_map["è¾“å…¥æ•°æ®/ç‰¹æ®Šä¿¡æ¯"]]).strip()
                    elif "è¾“å…¥æ•°æ®" in col_map:
                        input_data = str(row[col_map["è¾“å…¥æ•°æ®"]]).strip()
                    else:
                        input_data = ""
                    
                    # å°è¯•è·å–é¢„æœŸç»“æœï¼Œå¯èƒ½ä¸å­˜åœ¨
                    if "é¢„æœŸç»“æœ" in col_map:
                        expected = str(row[col_map["é¢„æœŸç»“æœ"]]).strip()
                    else:
                        expected = ""

                except Exception:
                    break
                if not step:
                    break
                data_rows.append([test_role, step, path, input_data, expected])  # åŒ…å«æ‰€æœ‰å­—æ®µï¼ŒåŒ…æ‹¬æµ‹è¯•è§’è‰²

            if not data_rows:
                print(f"âš ï¸ æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡: {sheet_name}")
                continue

            # === æ·»åŠ  Sheet äºŒçº§æ ‡é¢˜åˆ° DOCX ===
            sec_title = doc.add_heading(sheet_name, level=1)
            sec_title_run = sec_title.runs[0]
            sec_title_run.font.size = Pt(24)
            sec_title_run.font.bold = True
            sec_title_run.font.color.rgb = RGBColor(0, 0, 0)

            # === 1. ç”Ÿæˆå¹¶æ’å…¥ã€åœºæ™¯çº§é—®ç­”å¯¹ã€‘ï¼ˆæ¯ä¸ª Sheet ä»…ä¸€æ¬¡ï¼‰===
            steps_list = [row[1] for row in data_rows]  # row[1] æ˜¯æµ‹è¯•æ­¥éª¤
            summary_answer = generate_scene_summary(sheet_name, steps_list)

            # ğŸ”— æ‰‹åŠ¨æ‹¼æ¥æµ‹è¯•æ­¥éª¤é“¾ï¼ˆåŠ åœ¨ AI ç­”æ¡ˆå‰é¢ï¼‰
            steps_chain = " â†’ ".join(steps_list)
            prefixed_answer = f"æµ‹è¯•æ­¥éª¤å¦‚ä¸‹ï¼š{steps_chain}ã€‚\n\n{summary_answer}"

            # æ·»åŠ åˆ° DOCX
            doc.add_paragraph(f"ã€é—®é¢˜ã€‘{sheet_name}çš„æ•´ä½“æµ‹è¯•æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ")
            doc.add_paragraph(f"ã€ç­”æ¡ˆã€‘{prefixed_answer}")

            # æ·»åŠ åˆ° CSV
            qa_pairs.append({
                "é—®é¢˜": f"{sheet_name}çš„æ•´ä½“æµ‹è¯•æµç¨‹æ˜¯ä»€ä¹ˆï¼Ÿ",
                "é¢„æœŸå›ç­”": prefixed_answer
            })

            # === 2. ç”Ÿæˆå¹¶æ’å…¥ã€æ­¥éª¤çº§é—®ç­”å¯¹ã€‘ï¼ˆæ¯ä¸ªæ­¥éª¤ä¸€æ¡ï¼‰===
            for idx, (test_role, step, path, input_data, expected) in enumerate(data_rows, 1):
                # æ„å»ºé—®é¢˜
                question = f"å¦‚ä½•æµ‹è¯•{sheet_name}ä¸­çš„{step}ï¼Ÿ"
                
                # æ„å»ºç­”æ¡ˆ
                answer_lines = []
                # å¦‚æœæœ‰æµ‹è¯•è§’è‰²ï¼Œæ·»åŠ åˆ°ç­”æ¡ˆä¸­
                if test_role:
                    answer_lines.append(f"æµ‹è¯•è§’è‰²ï¼š{test_role}")
                answer_lines.extend([
                    f"æµ‹è¯•æ­¥éª¤ï¼š{step}",
                    f"åŠŸèƒ½è·¯å¾„ï¼š{path.replace('->', ' â†’ ')}",
                    f"è¾“å…¥æ•°æ® / ç‰¹æ®Šä¿¡æ¯ï¼š{input_data if input_data else '-'}",
                    f"é¢„æœŸç»“æœï¼š{expected if expected else '-'}"
                ])
                full_answer = "\n".join(answer_lines)
                
                # æ·»åŠ åˆ° DOCX
                doc.add_paragraph(f"ã€é—®é¢˜ã€‘{question}")
                doc.add_paragraph("ã€ç­”æ¡ˆã€‘")
                doc.add_paragraph(full_answer)
                doc.add_paragraph("")
                
                # æ·»åŠ åˆ° CSV
                qa_pairs.append({
                    "é—®é¢˜": question,
                    "é¢„æœŸå›ç­”": full_answer
                })

            doc.add_page_break()

    # ================== ä¿å­˜ DOCX ==================
    docx_file = os.path.join(OUTPUT_FOLDER, f"{main_title}.docx")
    
    # ğŸ”¥ å…³é”®ä¿®å¤ï¼šå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤ï¼Œé¿å…å°¾éƒ¨åƒåœ¾å­—èŠ‚
    if os.path.exists(docx_file):
        os.remove(docx_file)

    doc.save(docx_file)
    print(f"\nâœ… å·²ç”Ÿæˆ DOCX æ–‡ä»¶: {docx_file}")

    # ================== ä¿å­˜ CSV ==================
    csv_file = os.path.join(OUTPUT_FOLDER, f"{main_title}_qa.csv")
    print(f"ğŸ“„ å‡†å¤‡å†™å…¥ CSV æ–‡ä»¶: {csv_file}")

    # å†™å…¥ CSV æ–‡ä»¶ï¼Œä½¿ç”¨ UTF-8-SIG ç¼–ç ä»¥æ”¯æŒä¸­æ–‡
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(csv_file), exist_ok=True)
        
        # å°è¯•åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(csv_file):
            os.remove(csv_file)
            print(f"ğŸ”„ å·²åˆ é™¤æ—§æ–‡ä»¶")
        
        with open(csv_file, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=["é—®é¢˜", "é¢„æœŸå›ç­”"])
            writer.writeheader()
            writer.writerows(qa_pairs)
        
        print(f"âœ… å·²ç”Ÿæˆ CSV æ–‡ä»¶: {csv_file}")
        print(f"ğŸ‰ å…±æ”¶é›† {len(qa_pairs)} æ¡é—®ç­”å¯¹")
    except Exception as e:
        print(f"\nâŒ ç”Ÿæˆ CSV æ–‡ä»¶å¤±è´¥: {e}")
        # å°è¯•ä½¿ç”¨å½“å‰ç›®å½•ä½œä¸ºå¤‡é€‰
        alt_csv_file = os.path.join(os.getcwd(), f"{main_title}_qa.csv")
        print(f"ğŸ”„ å°è¯•ä½¿ç”¨å¤‡é€‰è·¯å¾„: {alt_csv_file}")
        try:
            with open(alt_csv_file, "w", encoding="utf-8-sig", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=["é—®é¢˜", "é¢„æœŸå›ç­”"])
                writer.writeheader()
                writer.writerows(qa_pairs)
            print(f"âœ… å·²ç”Ÿæˆ CSV æ–‡ä»¶ (å¤‡é€‰è·¯å¾„): {alt_csv_file}")
            print(f"ğŸ‰ å…±æ”¶é›† {len(qa_pairs)} æ¡é—®ç­”å¯¹")
        except Exception as e2:
            print(f"âŒ å¤‡é€‰è·¯å¾„å†™å…¥å¤±è´¥: {e2}")

    print(f"\nğŸ‰ å¤„ç†å®Œæˆ: {excel_file}")

def main():
    """
    ä¸»å‡½æ•°
    """
    # å¤„ç†æ‰€æœ‰ Excel æ–‡ä»¶
    excel_files = ["files/äººåŠ›åŠ©æ‰‹.xls"]
    
    for excel_file in excel_files:
        if os.path.exists(excel_file):
            process_excel_file(excel_file)
        else:
            print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {excel_file}")

if __name__ == "__main__":
    main()
